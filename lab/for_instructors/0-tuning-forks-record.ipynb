{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6884f06c-f78b-405b-860f-3aa47a48f670",
   "metadata": {},
   "source": [
    "# Getting to Know Audio Frequencies, Part 0 (Optional): Recording Tuning Forks\n",
    "\n",
    "**This part of the lab is optional but is strongly encouraged so that students can generate the sounds that we will be starting with.** If you are going to be working with the pre-recorded data only, then load the notebook entitled `1-visualizing-fork-sounds.ipynb` to proceed.\n",
    "\n",
    "**Objective:** Make digital recordings of tuning fork signals for use in later labs.\n",
    "\n",
    "\n",
    "**Required Materials**\n",
    "\n",
    "* Tuning forks: A (440 Hz) and E (329.6 Hz) recommended\n",
    "* Rubber hammer or padded surface for striking tuning fork\n",
    "* USB microphone (may be built-in on laptops, but a decent quality external mic is recommended)\n",
    "* Computer speakers\n",
    "* Python audio libraries noted below\n",
    "\n",
    "In  this part of the lab, students will:\n",
    "* Generate and make digital recordings of the sounds made by one or more tuning forks. \n",
    "* Save the digital recordings in a standard audio format (WAV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61a262-0a75-4606-8cb5-de205f7c2c0d",
   "metadata": {},
   "source": [
    "## Loading the Necessary Libraries\n",
    "\n",
    "Run each of the cells below, until you get to the  block titled **Recording the Tuning Fork(s)**. In  most cases, you can run a cell and advance to the next cell by clicking on the cell and pressing shift-Enter on the keyboard. The triangular \"play\" button in the widgets bar at the top of the notebook can also be used to run a selected cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91548c4a-fc18-48f7-845c-12e2e061bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this block will load the libraries needed \n",
    "# to capture, process, play, and display images of digitized sounds\n",
    "#\n",
    "# You will need typically need to install these (for instance, via pip) before\n",
    "# using this notebook\n",
    "# This is the minimum sound \n",
    "import scipy.io.wavfile as wavfile\n",
    "import sounddevice as sd\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d01d9-9a59-4ea7-bb97-1266e9df5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This library is used to plot the recorded data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a775346-2ce0-457e-97dd-b143a526168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this block loads some elements for adding interactive \n",
    "# widgets to the code\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import IPython.display as display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87ccc4-6af8-4277-8c30-a20144961bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block defines a function that can be used to capture audio\n",
    "# to a specified filename and for a specified duration. Read the \n",
    "# comments in the function for more details\n",
    "\n",
    "\n",
    "\n",
    "def record(filename, duration = 3, rate = 44100):\n",
    "    # Record audio from the system standard audio device, \n",
    "    # plot the output, and save the data as a WAV file.\n",
    "    #\n",
    "    # Audio is captured as soon as the function is run.\n",
    "    #\n",
    "    # Parameters\n",
    "    #     filename = name of file to save as (recommend using .wav extension)\n",
    "    #     duration = length of audio recording (defaults to 3s) \n",
    "    #     rate = sampling rate (44100 is widely compatible)\n",
    "    #\n",
    "    # Returns\n",
    "    #     rate = sampling rate (to have same outputs as wavfile.read() )\n",
    "    #     data = data in ndarray format\n",
    "    #\n",
    "    # Examples\n",
    "    # To record 3s to the file \"tuningA.wav\", call the function like\n",
    "    #     record(\"tuningA.wav\")\n",
    "    #\n",
    "    # To record 5s to the file \"voice.wav\", call the function like\n",
    "    #     record(\"voice.wav\", 5)\n",
    "    #\n",
    "    # Note that when you run  this block, the function is defined, but\n",
    "    # it will not record any audio until you call this function in a later block\n",
    "    #\n",
    "    # John M. Shea\n",
    "    # 6/1/2021\n",
    "\n",
    "   \n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    display.clear_output()\n",
    "    print(\"* recording\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(rate / CHUNK * duration)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "\n",
    "    print(\"* done recording\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    time=np.linspace(0, duration, int(rate/CHUNK*duration)*CHUNK)\n",
    "    #data=np.frombuffer(frames[0], dtype=np.int16)\n",
    "    #for frame in range(1,len(frames)):\n",
    "    #    data=np.hstack((data, np.frombuffer(frames[frame], dtype=np.int16)))\n",
    "    data = np.frombuffer(b''.join(frames), dtype=np.int16)\n",
    "    \n",
    "    plt.plot(time, data)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Relative sound pressure')\n",
    "\n",
    "    \n",
    "    return rate, data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17cd73-3787-4476-8a75-7bfd20d1f083",
   "metadata": {},
   "source": [
    "## Recording the Tuning Fork(s)\n",
    "\n",
    "This discussion assumes you have A (440 Hz) and E (329.6 Hz) tuning forks. If you are using different tuning forks, you may want to modify the code to match the tuning forks in your collection.\n",
    "\n",
    "To record the audio from the A tuning fork:\n",
    "\n",
    "1. Be sure everyone and all devices in the room are quiet for the recording\n",
    "1. Strike the fork using a rubber mallet, or strike the fork on a soft surface, such as your knee,  a padded table, or even the inside of a book. If using a table or a book, strike the side of the tuning fork flat on the surface. \n",
    "2. **Immediately** hold the tuning fork close to your mic and execute the code block below (typically, by selecting it and pressing shift-Enter).  **Hint:** Whatever key or mouse button you press to execute the cell, **do not release it** until the recording is done. This will prevent the sound of the key/button being release from appearing in your recording. However, it may execute additional cells that you did not plan to run.\n",
    "4. If you have any problems during the recording process, you can rerun that cell as many times as necessary.\n",
    "\n",
    "You should see a plot that visualizes the captured audio. It may look something like the following previously captured tuning fork data:\n",
    "\n",
    "![Example Tuning Fork Recording Output](../plots/EForkCapture.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63824511-1600-4a31-a982-807f432a7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "rateA, dataA=record('forkA.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66511d6-a10e-4efd-a833-873e02deb435",
   "metadata": {},
   "source": [
    "If you also have an E tuning fork:\n",
    "\n",
    "1. Again, be sure that everyone and all devices in the room are quiet for the recording.\n",
    "1. Strike the fork using a rubber mallet, or strike the fork on a soft surface, such as your knee or a padded table.\n",
    "2. **Immediately** hold the tuning fork close to your mic and press execute the code below:\n",
    "4. As before, you can rerun the recording cell as many times as necessary to get a clean recording.\n",
    "\n",
    "**Note that the block below may be run after the A fork is recorded if you held down the key or button used to execute the cell, as instructed. If it already ran, that is no problem. Just click on the cell below and use shift-Enter or the \"play\" button to rerun it when you are ready.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08947e72-7507-4773-b917-fed2dfb9a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rateE, dataE=record('forkE.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af40a6-1f86-4e41-b7b2-948344f86f77",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If you think you have a good recording of your tuning fork(s), then you are ready to move on to notebook `1-visualizing-fork-sounds.ipynb`.  Load that notebook to start visualizing and comparing the data from the forks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
